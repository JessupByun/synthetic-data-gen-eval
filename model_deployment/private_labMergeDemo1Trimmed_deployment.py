import os
import pandas as pd
from sklearn.model_selection import train_test_split
from dotenv import load_dotenv
from groq import Groq

# Load the real data
data_csv = "data/real_data/private_labMergeDemo1Trimmed/private_labMergeDemo1Trimmed.csv"
data = pd.read_csv(data_csv)

# Split the data into train and test sets
train_data, test_data = train_test_split(data, test_size=0.8, random_state=42)
test_data.to_csv('data/real_data/private_labMergeDemo1Trimmed/private_labMergeDemo1Trimmed_test.csv', index=True)
train_data.to_csv('data/real_data/private_labMergeDemo1Trimmed/private_labMergeDemo1Trimmed_train.csv', index=False) # Will include the entire training data, which will then be sampled in n sample sizes below.

# Define the n sample size of train_data
train_data = train_data.sample(250)

# Define temperature parameter for model (controls randomness and diversity, as temp -> 0, model becomes more deterministic and repetitive)
temperature = 1

# Load environment variables from the .env file
load_dotenv()

# Access the Groq API key (should be securely stored in the .env file (not provided, must be generated by user))
api_key = os.getenv("GROQ_API_KEY")

# Instantiate the Groq client with API key
client = Groq(api_key=api_key)

# List of model ID names that will be deployed. Visit groq API documentation for more models
model_names = ["llama-3.1-70b-versatile"] #, "llama-3.1-8b-instant", "llama-3.2-1b-preview"] mixtral-8x7b-32768 llama-3.1-70b-versatile

# This prompt structure is adapted from the prompt example B.5. from the research paper: "Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in low-data regimes" (Seedatk, Huynh, et al.) https://arxiv.org/pdf/2312.12112 
# The template is currently adapted to the 'insurance.csv' dataset (referenced in README.md)
prompt_template_baseline = """
System role: You are a tabular synthetic data generation model.

You are a synthetic data generator.
Your goal is to produce data which mirrors the given examples in causal structure and feature and label distributions but also produce as diverse samples as possible.

I will give you real examples first.

Context: Leverage your knowledge about healthcare, demographics, and patient data to generate 1000 realistic but diverse samples. 
Output the data in a csv format where I can directly copy and paste into a csv.

Example data: {data}

The output should use the following schema:

"subject_id_x": integer // feature column for the unique identifier of the patient
"admittime_y": string // feature column for the admission time and date (ISO datetime format)
"dischtime": string // feature column for the discharge time and date (ISO datetime format)
"Age": integer // feature column for the age of the patient at the time of admission
"gender": string // feature column for the gender of the patient
"ethnicity": string // feature column for the reported ethnicity of the patient
"insurance": string // feature column for the type of insurance coverage of the patient
"label": integer // feature column indicating a binary outcome (e.g., event occurrence or not)
"dod": string // feature column for the date of death, if applicable (ISO datetime format)
"charttime": string // feature column for the time and date of a lab or clinical chart event (ISO datetime format)
"admittime_x": string // feature column for a secondary admission time used for lab-related calculations (ISO datetime format)
"lab_time_from_admit": float // feature column for the time elapsed in hours from admission to lab measurement
"valuenum": float // label column for the numerical result of a lab test or clinical measurement

DO NOT COPY THE EXAMPLES but generate realistic but new and diverse samples which have the correct label conditioned on the features.
"""

prompt_template_advanced = """
System role: You are a tabular synthetic data generation model.

You are a synthetic data generator.
Your goal is to produce data which mirrors the given examples in causal structure and feature and label distributions but also produce as diverse samples as possible.

I will give you real examples first.

Context: Leverage your knowledge about healthcare, demographics, and patient data to generate 1000 realistic but diverse samples.
Output the data in a csv format where I can directly copy and paste into a csv.

Example data: {data}

The output should use the following schema:

subject_id_x (integer): Unique identifier for the patient in the dataset.
admittime_y (string, ISO datetime): The admission date and time for this particular hospitalization.
dischtime (string, ISO datetime): The discharge date and time for this hospitalization.
Age (integer): Age of the patient at the time of admission.
gender (string): The patient's reported gender (e.g., "M" for male, "F" for female).
ethnicity (string): The patient's reported ethnicity (e.g., "WHITE", "BLACK/AFRICAN AMERICAN", "HISPANIC/LATINO").
insurance (string): The type of insurance coverage the patient had during the hospital stay (e.g., "Medicare", "Medicaid", "Other").
label (integer): A binary outcome indicator, where 0 might represent no event of interest and 1 an event. In this sample, all are 0.
dod (string, ISO datetime): Date of death. If "1970-01-01", it indicates no death recorded.
charttime (string, ISO datetime): The date and time a particular lab test or clinical measurement was recorded.
admittime_x (string, ISO datetime): Another admission timestamp used to calculate lab test timing.
lab_time_from_admit (float): The elapsed time in hours from the admission to when the lab measurement was taken. Positive values indicate time after admission, negative values might indicate adjusted or pre-admission data entry times.
valuenum (float): A numeric value representing a lab test result or clinical measurement result.

Here are detailed summary stats that you should also use:

,count,unique,top,freq,mean,std,min,25%,50%,75%,max
subject_id_x,78723.0,,,,10020437.9889867,12041.026420660546,10000032.0,10010867.0,10019003.0,10032725.0,10040025.0
admittime_y,78723,271,2140-01-23 16:19:00,2261,,,,,,,
dischtime,78723,271,2140-02-26 18:15:00,2261,,,,,,,
Age,78723.0,,,,61.13121959274926,13.56463866223975,21.0,53.0,63.0,69.0,91.0
gender,78723,2,M,46614,,,,,,,
ethnicity,78723,14,WHITE,51329,,,,,,,
insurance,78723,3,Other,45624,,,,,,,
label,78723.0,,,,0.13805368189728542,0.34495851112158016,0.0,0.0,0.0,0.0,1.0
dod,78723,32,1970-01-01,40929,,,,,,,
charttime,78723,5031,2115-11-08 13:00:00,57,,,,,,,
admittime_x,78723,271,2140-01-23 16:19:00,2261,,,,,,,
lab_time_from_admit,78723.0,,,,7693.055676231851,9077.037248347231,-1372.0,1032.0,4434.0,11067.5,62815.0
valuenum,78723.0,,,,70.0171414580237,1015.2877738600624,-780.0,3.8,15.3,48.45,169000.0

Make sure to provide many sample rows in your output
DO NOT COPY THE EXAMPLES but generate realistic but new and diverse samples which have the correct label conditioned on the features.
"""

# Function to generate synthetic data using a model and prompt
def generate_synthetic_data(model_name, data):

    prompt = prompt_template_advanced.format(data = data)
    
    try:
        # Create a chat completion using the Groq API
        response = client.chat.completions.create(
            messages=[
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            model=model_name,
            #response_format={"type": "json_object"} Turn on for JSON beta mode
            temperature=temperature
        )
        
        # Print the full response for debugging
        print("Full Response:", response)
        
        generated_data = response.choices[0].message.content if response.choices else "No output"
        
        return generated_data
    except Exception as e:
        print(f"Error generating data with model {model_name}: {e}")
        return None

# Main function to run the process
def main():
    
    for model_name in model_names:
        print(f"Generating data with {model_name}...")
        
        # Generate synthetic data with n rows!
        data = generate_synthetic_data(model_name, train_data)

        print(f"Generated Data for {model_name}:\n{data}\n")

if __name__ == "__main__":
    main()